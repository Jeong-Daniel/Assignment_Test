# Assignment_Test

## Environment  
Python 3.9.13  
requirements.txt  
+
CUDA를 이용한 학습을 위해서는 아래 명령어 입력 필요(Window, Anaconda 기준)
conda install pytorch torchvision cudatoolkit=11.6 -c pytorch -c conda-forge  

![dir_paht](https://github.com/Jeong-Daniel/Assignment_Test/blob/main/Cap%202022-09-26%2009-26-54-703.png)
데이터와 노트북은 같은 폴더에 넣었습니다.

**[Question]**
1) 제안한 모델(들)을 사용한 이유와 근거를 간략히 적어주세요.
2) 성능을 향상시키기 위해 노력했다면, 그 내용과 근거를 간략히 적어주세요.
3) 결과에 대한 본인의 해석을 간략히 적어주세요.
4) 만약 시간이 더 주어진다면 가장 시도해보고 싶은 것을 하나 제시하고 그 이유에 대해서 간략히 적어주세요.

주어진 조건에 따라서 대답을 작성하는게 맞지만 사실상 목표하는 모델 학습을 달성하지 못해서 따로 작성을 하겠습니다.

* 개요  


배경과 크랙을 구분하는 문제로 보고 segmentation-models-pytorch 라이브러리를 사용해서 모델을 만들어 볼려고 했습니다. 하지만 인코더와 모델을 여러가지 조합으로 시도를 교체해보았지만 사실상 학습을 실패한 것으로 보았습니다.

* 문제원인  


segmentation-models-pytorch 라이브러리와 다른 객체 검출 미세 조정 예제는 모두 분명한 경계와 그 경계를 바탕으로 하나의 객체로 구분이 됩니다. 윤곽선 검출(Edge Detection) 알고리즘을 기준으로 보았을때 미분을 수행하게 되면 색상 값 차이값을 바탕으로 경계지점에 대한 분명한 결과를 얻을 수 있지만 크랙 문제에 있어서는 보는 관점이 사뭇 달라서 시도한 방법은 유효하지 않은 것으로 보입니다.

크랙의 경우 부분적이거나 하나의 선으로 표시가 되며 크랙의 규모가 크지 않다면 배경과 분명하게 분리된 하나의 객체로 인식되기 어려웠습니다. 더해서 크랙은 배경이 되는 물질과 동일한 재료로 이루어져있기에 색상에서 분명하게 구분되는 것 보다 음영으로 주로 구분이 이루어지는데 이것도 모델이 ROI를 파악하는데 어려움이 있는 것으로 생각 합니다.

마지막으로 전체 배경에 비해서 목표하는 크랙은 적은 부분을 차지하는 경우가 많았기에 크랙을 발견하지 못했다고 처리를 해도 IoU에서 높은 점수를 얻은 것으로 보았습니다. 사진 데이터에서 크랙의 부위가 큰 것을 중심으로 오버샘플링을 하고 augmentation을 수행하는 것을 시도 해볼 수 있을 듯합니다.

* 해보고 싶은 것  


segmentation-models-pytorch 라이브러리 대신 torchvision.models.detection을 이용해서 모델을 만들어 보고 싶습니다. 다른 평가방법을 도입하는 것도 smp에 넣는 것 보다는 torch에서 넣는 편이 나을거 같다는 생각이 들었습니다.

* 마무리  


결과적으로 목표하는 모델학습을 달성하지는 못했지만 1주일간 객체 검출에 대해서 고민을 하고 공부를 해보는 기회가 되었습니다. 기회를 주셔서 감사합니다.
